{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/deploy-to-cloud/model-register-and-deploy.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/deploy-to-cloud/model-register-and-deploy.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Register Model and deploy as Webservice\n\nThis example shows how to deploy a Webservice in step-by-step fashion:\n\n 1. Register Model\n 2. Deploy Model as Webservice"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Prerequisites\nIf you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the [configuration](../../../configuration.ipynb) Notebook first if you haven't."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Check core SDK version number\nimport azureml.core\n\nprint(\"SDK version:\", azureml.core.VERSION)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Initialize Workspace\n\nInitialize a workspace object from persisted configuration."
    },
    {
      "metadata": {
        "tags": [
          "create workspace"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace\n\nws = Workspace.from_config()\nprint(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Register Model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can add tags and descriptions to your Models. Note you need to have a `sklearn_regression_model.pkl` file in the current directory. This file is generated by the 01 notebook. The below call registers that file as a Model with the same name `sklearn_regression_model.pkl` in the workspace.\n\nUsing tags, you can track useful information such as the name and version of the machine learning library used to train the model. Note that tags must be alphanumeric."
    },
    {
      "metadata": {
        "tags": [
          "register model from file"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.model import Model\n\nmodel = Model.register(model_path=\"sklearn_regression_model.pkl\",\n                       model_name=\"sklearn_regression_model.pkl\",\n                       tags={'area': \"diabetes\", 'type': \"regression\"},\n                       description=\"Ridge regression model to predict diabetes\",\n                       workspace=ws)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create Environment"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can now create and/or use an Environment object when deploying a Webservice. The Environment can have been previously registered with your Workspace, or it will be registered with it as a part of the Webservice deployment. Only Environments that were created using azureml-defaults version 1.0.48 or later will work with this new handling however.\n\nMore information can be found in our [using environments notebook](../training/using-environments/using-environments.ipynb)."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core import Environment\n\nenv = Environment.from_conda_specification(name='deploytocloudenv', file_path='myenv.yml')\n\n# This is optional at this point\n# env.register(workspace=ws)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Create Inference Configuration\n\nThere is now support for a source directory, you can upload an entire folder from your local machine as dependencies for the Webservice.\nNote: in that case, your entry_script, conda_file, and extra_docker_file_steps paths are relative paths to the source_directory path.\n\nSample code for using a source directory:\n\n```python\ninference_config = InferenceConfig(source_directory=\"C:/abc\",\n                                   runtime= \"python\", \n                                   entry_script=\"x/y/score.py\",\n                                   conda_file=\"env/myenv.yml\", \n                                   extra_docker_file_steps=\"helloworld.txt\")\n```\n\n - source_directory = holds source path as string, this entire folder gets added in image so its really easy to access any files within this folder or subfolder\n - runtime = Which runtime to use for the image. Current supported runtimes are 'spark-py' and 'python\n - entry_script = contains logic specific to initializing your model and running predictions\n - conda_file = manages conda and python package dependencies.\n - extra_docker_file_steps = optional: any extra steps you want to inject into docker file"
    },
    {
      "metadata": {
        "tags": [
          "create image"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.model import InferenceConfig\n\ninference_config = InferenceConfig(entry_script=\"score.py\", environment=env)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Deploy Model as Webservice on Azure Container Instance\n\nNote that the service creation can take few minutes."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice, Webservice\nfrom azureml.exceptions import WebserviceException\n\ndeployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\naci_service_name = 'aciservice1'\n\ntry:\n    # if you want to get existing service below is the command\n    # since aci name needs to be unique in subscription deleting existing aci if any\n    # we use aci_service_name to create azure aci\n    service = Webservice(ws, name=aci_service_name)\n    if service:\n        service.delete()\nexcept WebserviceException as e:\n    print()\n\nservice = Model.deploy(ws, aci_service_name, [model], inference_config, deployment_config)\n\nservice.wait_for_deployment(True)\nprint(service.state)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Test web service"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import json\ntest_sample = json.dumps({'data': [\n    [1,2,3,4,5,6,7,8,9,10], \n    [10,9,8,7,6,5,4,3,2,1]\n]})\n\ntest_sample_encoded = bytes(test_sample, encoding='utf8')\nprediction = service.run(input_data=test_sample_encoded)\nprint(prediction)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Delete ACI to clean up"
    },
    {
      "metadata": {
        "tags": [
          "deploy service",
          "aci"
        ],
        "trusted": false
      },
      "cell_type": "code",
      "source": "service.delete()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Model Profiling\n\nYou can also take advantage of the profiling feature to estimate CPU and memory requirements for models.\n\n```python\nprofile = Model.profile(ws, \"profilename\", [model], inference_config, test_sample)\nprofile.wait_for_profiling(True)\nprofiling_results = profile.get_results()\nprint(profiling_results)\n```"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Model Packaging\n\nIf you want to build a Docker image that encapsulates your model and its dependencies, you can use the model packaging option. The output image will be pushed to your workspace's ACR.\n\nYou must include an Environment object in your inference configuration to use `Model.package()`.\n\n```python\npackage = Model.package(ws, [model], inference_config)\npackage.wait_for_creation(show_output=True)  # Or show_output=False to hide the Docker build logs.\npackage.pull()\n```\n\nInstead of a fully-built image, you can also generate a Dockerfile and download all the assets needed to build an image on top of your Environment.\n\n```python\npackage = Model.package(ws, [model], inference_config, generate_dockerfile=True)\npackage.wait_for_creation(show_output=True)\npackage.save(\"./local_context_dir\")\n```"
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "aashishb"
      }
    ],
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}